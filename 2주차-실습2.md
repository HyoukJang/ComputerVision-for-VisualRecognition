# MNIST 데이터셋을 통한 SVM 학습
* 

## *본 파일 실행을 위해 [data2의 MNIST.zip](https://github.com/moduPlayGround/ComputerVision-for-VisualRecognition/blob/master/2%EC%A3%BC%EC%B0%A8-%EC%8B%A4%EC%8A%B5/data2/MNIST.zip)의 압축을 풀어야하며, .xml 데이터를 받으셔야합니다. 데이터파일 모두 .cpp 파일이 있는 폴더와 같은 곳에 첨부해주시길 바랍니다.

<br> 

## MNIST 데이터 HOG(Histogram of Gradient)로 특징량 검출

### HOG : [참고가 될 설명](https://donghwa-kim.github.io/hog.html)


### Input Iamge Information : 20x20의 MNIST Image 5000장 (각 클래스(0~9) 별 500장)

#### 가장먼저 HOG Descriptor를 추출할 이미지를 OPenCV의 `imread`를 이용해 불러옵니다. 이번 실습에서 제공하는 MNIST Image의 이름 정의에 대해서 'data 4_122'를 예로들어 간단히 설명하자면,'data 4_122'라는 이름을 갖는 이미지는 4를 나타내는 손글씨 사진 중 122번째를 의미합니다. 0~9까지의 숫자를 손글씨로 작성하였고 각 클래스별로 총 500장이 있습니다.

```C++
		cout << "\n//////////////////////////////////////////////////////" << endl;

	cout << "train Image load" << endl;

	for(int num=0; num<10; num++)
	{
		cout << num << " image load" << endl;
		for (int i = 0; i < NUMBER_train; i++)
		{
			Mat MNIST = imread("./MNIST/data "+ std::to_string(num) + "_" +std::to_string(i + 1) + ".PNG",COLOR_RGB2GRAY);
			if (!(MNIST.data))
			{
				cout << "image load fail" << endl;
				return 0;
			}
			HOG_train_data.push_back(find_HOG_feature_image(MNIST));
			HOG_train_data_label.push_back(num);
		}

	}
	cout << "\n//////////////////////////////////////////////////////" << endl;
	

```

#### 다음으로는 OPencv에서 제공하는 HOGDescriptor class를 통해서 HOGDescriptor를 계산해야합니다. 이 과정을 진행하는 함수는 다음과 같습니다.

```C++
vector<float> find_HOG_feature_image(Mat img)
{
	HOGDescriptor IMAGE_HOG
	(
		Size(20, 20), //winSize
		Size(8, 8), //blocksize
		Size(4, 4), //blockStride,
		Size(8, 8), //cellSize,
		9, //nbins,
    /////////////// 밑에 파라미터는 추가적으로 공부하시길 바랍니다.
		1, //derivAper,
		-1, //winSigma,
		0, //histogramNormType,
		0.2, //L2HysThresh,
		0,//gammal correction,
		64//nlevels=64
	);

	vector<float> hog_descriptor;
	IMAGE_HOG.compute(img, hog_descriptor);
	return hog_descriptor;

}
```
![ezgif com-gif-maker](https://user-images.githubusercontent.com/44772344/52755939-0c5eeb00-3043-11e9-9e1c-c9a236566788.gif) <br>

#### HOGDescriptor를 사용하기위해 `HOGDescriptor IMAGE_HOG` 와 같이 설정합니다. 다만 이 과정에서 자신이 입력할 이미지에 따라 Block size, Block Stride, cell size를 설정해주고 총 몇개의 회전방향을 구분할지 nbins를 설정해주면 됩니다. 이후의 변수들은 일반적으로는 디폴트 값을 설정합니다. 이 과정을 통해서 입력한 MNIST 이미지 5000장에 대한 `HOG Decriptor`를 추출해 저장합니다. 이 때  `HOG Decriptor`는 `vector<vector<float>>`의 형태로 저장되고 있습니다. 이후에는 SVM(Support Vector Machine)을 통해서 분류를 진행할 예정인데, OPENCV에서 주어지는 SVM함수는 다음과 같이 Mat 형태를 argument로 요구하고 있습니다. 따라서 `ConvertVectortoMatrix` 함수를 통해서 `vector<vector<float>>`형태로 저장한 `HOG Decriptor`를 Mat 형태로 변환해줍니다. 

```C++
	int descriptor_size = HOG_train_data[0].size();

	Mat HOG_train_data_Mat(HOG_train_data.size(), descriptor_size, CV_32FC1);
	Mat HOG_test_data_Mat(HOG_test_data.size(), descriptor_size, CV_32FC1);
	Mat HOG_train_data_label_Mat(HOG_train_data_label.size(), 1, CV_32FC1);
	Mat HOG_test_data_label_Mat(HOG_test_data_label.size(), 1, CV_32FC1);

	ConvertVectortoMatrix(HOG_train_data, HOG_test_data, HOG_train_data_Mat, HOG_test_data_Mat);

	for (int i = 0; i < HOG_train_data_label.size(); i++)
	{
		HOG_train_data_label_Mat.at<float>(i, 0) = HOG_train_data_label[i];
	}
	for (int i = 0; i < HOG_test_data_label.size(); i++)
	{
		HOG_test_data_label_Mat.at<float>(i, 0) = HOG_test_data_label[i];
	}
	
	
	..(생략)..
	
	
	void ConvertVectortoMatrix(vector<vector<float> > &trainHOG, vector<vector<float> > &testHOG, Mat &trainMat, Mat &testMat)
{

	int descriptor_size = trainHOG[0].size();

	for (int i = 0; i < trainHOG.size(); i++)
	{
		for (int j = 0; j < descriptor_size; j++) 
		{
			trainMat.at<float>(i, j) = trainHOG[i][j];
		}
	}
	for (int i = 0; i < testHOG.size(); i++)
	{
		for (int j = 0; j < descriptor_size; j++)
		{
			testMat.at<float>(i, j) = testHOG[i][j];
		}
	}
}

```
#### 다음과 같이 vector에서 Mat 형태로 변환했다면 이제 SVM을 이용해서 분류를 진행합니다. SVM을 이용하기 위해서는 직접 파라미터를 수정할 수도 있고 `train_auto`를 통해서 자동으로 구할 수 있습니다. 이 예제에서는 자동으로 구했으며, `train_auto`실행할 경우 오랜 시간이 소모됩니다. 따라서 미리 실행해서 구한 svm 파일을 올려놨으니 [MNIST_HOG_SVM_Linear_acc97.xml](https://github.com/moduPlayGround/ComputerVision-for-VisualRecognition/blob/master/2%EC%A3%BC%EC%B0%A8-%EC%8B%A4%EC%8A%B5/data2/MNIST_HOG_SVM_Linear_acc97.xml) 이 부분을 건너뛰고 싶으시다면, [예제1_2](https://github.com/moduPlayGround/ComputerVision-for-VisualRecognition/blob/master/2%EC%A3%BC%EC%B0%A8-%EC%8B%A4%EC%8A%B5/Example_002_1_2.cpp)로 넘어가시면 됩니다.

```C++

	cout << "\n//////////////////////////////////////////////////////" << endl;
	cout << "                      svm setting                      " << endl;
	cout << "//////////////////////////////////////////////////////\n" << endl;

	CvSVM svm;

	CvSVMParams params = CvSVMParams
    (
	  CvSVM::C_SVC,   // Type of SVM, here N classes (see manual)
	  CvSVM::LINEAR,  // kernel type (see manual)
	  0.0,            // kernel parameter (degree) for poly kernel only
	  0.0,            // kernel parameter (gamma) for poly/rbf kernel only
	  0.0,            // kernel parameter (coef0) for poly/sigmoid kernel only
	  10,             // SVM optimization parameter C
	  0,              // SVM optimization parameter nu (not used for N classe SVM)
	  0,              // SVM optimization parameter p (not used for N classe SVM)
	  NULL,           // class wieghts (or priors)
	  // Optional weights, assigned to particular classes.
	  // They are multiplied by C and thus affect the misclassification
	  // penalty for different classes. The larger weight, the larger penalty
	  // on misclassification of data from the corresponding class.

	  // termination criteria for learning algorithm

	  cvTermCriteria(CV_TERMCRIT_ITER + CV_TERMCRIT_EPS, 1000, 0.000001)

   );

	cout << "\n//////////////////////////////////////////////////////" << endl;
	cout << "                      svm train                      " << endl;
	cout << "//////////////////////////////////////////////////////\n" << endl;

	svm.train_auto(HOG_train_data_Mat, HOG_train_data_label_Mat, Mat(), Mat(), params, 10);

	cout << "\n//////////////////////////////////////////////////////" << endl;
	cout << "                      svm save                   " << endl;
	cout << "//////////////////////////////////////////////////////\n" << endl;

	svm.save("MNIST_HOG_SVM.xml");


```

#### 해당 과정에 대해서 설명하자면, 해당 입력으로 들어가는 파라미터에 대한 값은 실험적으로 가장 높은 정확도를 보이는 파라미터를 구해야합니다. 이에 대한 과정은 해당 실습에서는 생략하겠습니다. 해당 코드에서는 실험을 통해서 구한 파라미터인 `params.gamma = 0.50625`와 `params.C = 2.5`를 입력했습니다. 이러한 파라미터를 갖는 SVM을 생성한 후 학습을 위해서 데이터를 입력합니다. SVM을 학습하기위해서는 (OPencv2.4버전기준) 위에서  구한`HOG Decriptor`를 포함하는 Mat 과 각 `HOG Decriptor`가 가르키는 Label 값을 정리한 Mat을 입력해줘야 합니다. 좀 더 쉽게 설명하자면 다음과 같습니다. 

![svm_input](https://user-images.githubusercontent.com/44772344/52757499-2f3fce00-3048-11e9-8af6-a5f6d723ea6a.png)

#### 다음과 같은 데이터를 `svm.train`에 입력하면 분류기는 자동으로 입력된 데이터들을 라벨에 따라서 구분짓고 이후에 데이터가 들어왔을때 들어온 데이터가 어떠한 영역에 해당되는지에 대한 예측을 진행할 수 있습니다. 

#### 학습을 마쳤다면 이제 예측을 진행해보겠습니다. 위에서 train 이미지를 불러온 방법과 마찬가지로 이전에 불러온적 없는 test 이미지를 불러오고 각 이미지에 대한 descriptor를 구합니다. 그리고 이 구한 descriptor를 svm에 넣어서 어떠한 결과가 나오는지 정확도를 구합니다. 이때 정확도는 test 데이터에 대한 라벨 정보를 갖고 있기 때문에 Svm으로 분류된 값이랑 기존 label 값이랑 비교해 구할 수 있습니다. 해당 파트에 대한 부분은 다음에서 확인할 수 있습니다.

```C++
svm.predict(MNIST_test_HOG_Mat, testResponse);

	float count = 0, accuracy = 0;
	for (int i = 0; i < testResponse.rows; i++)
	{
		if (testResponse.at<float>(i, 0) == MNIST_test_label[i])
		{
			count = count + 1;
		}
	}

	accuracy = (count / testResponse.rows) * 100;


	cout << "accuracy : " << accuracy << endl;
```

#### 해당 과정을 통한 이번 이미지에 대한 정확도는 약 97%가 나오는것을 확인할 수 있습니다. 추가적으로 매번 train 이미지의 descriptor를 구하고 svm을 train하는 과정은 이번 실습에서는 5000장이였지만, 이미지가 많아지면 많은 시간이 소모됩니다. 따라서 학습한 svm을 다음과 같이 저장해서 다음에는 바로 svm.predict을 진행할 수 있습니다.

```C++
	
	cout << "\n//////////////////////////////////////////////////////" << endl;
	cout << "                      svm predict                      " << endl;
	cout << "//////////////////////////////////////////////////////\n" << endl;
	
	Mat Response_test;
	Mat Response_train;
	
	svm.predict(HOG_train_data_Mat, Response_train);
	float count_train = 0, accuracy_train = 0;
	for (int i = 0; i < Response_train.rows; i++)
	{
		if (Response_train.at<float>(i, 0) == HOG_train_data_label[i])
		{
			count_train = count_train + 1;
		}
	}

	svm.predict(HOG_test_data_Mat, Response_test);
	float count_test = 0, accuracy_test = 0;
	for (int i = 0; i < Response_test.rows; i++)
	{
		if (Response_test.at<float>(i, 0) == HOG_test_data_label[i])
		{
			count_test = count_test + 1;
		}
	}

	accuracy_train = (count_train / Response_train.rows) * 100;
	cout << "accuracy_train : " << accuracy_train << endl;
	accuracy_test = (count_test / Response_test.rows) * 100;
	cout << "accuracy_test : " << accuracy_test << endl;
	
```
####  이 예제에서는 약 97%의 정확도를 보이고 있습니다. 
